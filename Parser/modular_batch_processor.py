#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å—åŒ–IPTVæ‰¹é‡å¤„ç†å™¨
ä½¿ç”¨æ¨¡å—åŒ–æœç´¢å™¨æ¥å£ï¼Œæ”¯æŒå¤šç§ç«™ç‚¹åˆ‡æ¢
"""

import os
import time
import logging
import re
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from urllib.parse import urlparse
from collections import Counter

# å¯¼å…¥æœç´¢å™¨æ¥å£å’Œå®ç°
from searcher_interface import BaseIPTVSearcher, IPTVChannel, SearchConfig, SearcherFactory
from tonkiang_searcher import TonkiangSearcher

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class ChannelGroup:
    """é¢‘é“åˆ†ç»„æ•°æ®ç±»"""
    name: str              # åˆ†ç»„åç§°
    channels: List[str]    # é¢‘é“åç§°åˆ—è¡¨


class ChannelFileParser:
    """é¢‘é“æ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def parse_channel_file(filename: str = "LiveChannel.txt") -> List[ChannelGroup]:
        """
        è§£æé¢‘é“åˆ—è¡¨æ–‡ä»¶
        
        Args:
            filename: è¾“å…¥æ–‡ä»¶å
            
        Returns:
            List[ChannelGroup]: è§£æå‡ºçš„é¢‘é“åˆ†ç»„åˆ—è¡¨
        """
        groups = []
        current_group = None
        
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†ç»„æ ‡é¢˜ï¼ˆä»¥#å¼€å¤´ï¼‰
                    if line.startswith('#'):
                        # å¦‚æœæœ‰å½“å‰åˆ†ç»„ï¼Œå…ˆä¿å­˜
                        if current_group and current_group.channels:
                            groups.append(current_group)
                        
                        # åˆ›å»ºæ–°åˆ†ç»„
                        group_name = line[1:].strip()  # ç§»é™¤#å·
                        current_group = ChannelGroup(name=group_name, channels=[])
                    
                    else:
                        # é¢‘é“åç§°
                        if current_group is None:
                            # å¦‚æœæ²¡æœ‰åˆ†ç»„ï¼Œåˆ›å»ºé»˜è®¤åˆ†ç»„
                            current_group = ChannelGroup(name="é»˜è®¤åˆ†ç»„", channels=[])
                        
                        current_group.channels.append(line)
                
                # ä¿å­˜æœ€åä¸€ä¸ªåˆ†ç»„
                if current_group and current_group.channels:
                    groups.append(current_group)
        
        except FileNotFoundError:
            logger.error(f"æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {filename}")
            raise
        except Exception as e:
            logger.error(f"è§£ææ–‡ä»¶å¤±è´¥: {e}")
            raise
        
        return groups


class DomainFrequencyProcessor:
    """åŸŸåé¢‘ç‡å¤„ç†å™¨ - æ ¹æ®åŸŸå/IPå‡ºç°é¢‘ç‡æ’åºé“¾æ¥"""
    
    def __init__(self):
        self.domain_counter = Counter()
    
    def extract_domain_or_ip(self, url: str) -> str:
        """
        ä»URLä¸­æå–åŸŸåæˆ–IPåœ°å€
        
        Args:
            url: è¾“å…¥URL
            
        Returns:
            str: åŸŸåæˆ–IPåœ°å€
        """
        try:
            parsed = urlparse(url)
            hostname = parsed.hostname
            
            if hostname:
                # æ£€æŸ¥æ˜¯å¦ä¸ºIPåœ°å€
                ip_pattern = r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$'
                if re.match(ip_pattern, hostname):
                    return hostname  # è¿”å›IPåœ°å€
                else:
                    return hostname  # è¿”å›åŸŸå
            
            return url  # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸURLä½œä¸ºfallback
            
        except Exception:
            return url
    
    def collect_domain_stats(self, all_channels: Dict[str, Dict[str, List[IPTVChannel]]]):
        """
        æ”¶é›†æ‰€æœ‰é“¾æ¥çš„åŸŸåç»Ÿè®¡
        
        Args:
            all_channels: æ‰€æœ‰é¢‘é“æ•°æ®
        """
        logger.info("å¼€å§‹ç»Ÿè®¡åŸŸå/IPå‡ºç°é¢‘ç‡...")
        
        for group_name, group_channels in all_channels.items():
            for channel_name, channels in group_channels.items():
                for channel in channels:
                    domain = self.extract_domain_or_ip(channel.url)
                    self.domain_counter[domain] += 1
        
        logger.info(f"ç»Ÿè®¡å®Œæˆï¼Œå‘ç° {len(self.domain_counter)} ä¸ªä¸åŒçš„åŸŸå/IP")
        
        # æ˜¾ç¤ºTop 10åŸŸå/IP
        top_domains = self.domain_counter.most_common(10)
        logger.info("å‡ºç°é¢‘ç‡æœ€é«˜çš„åŸŸå/IP:")
        for i, (domain, count) in enumerate(top_domains, 1):
            logger.info(f"  {i:2d}. {domain} ({count} æ¬¡)")
    
    def sort_channels_by_domain_frequency(self, channels: List[IPTVChannel]) -> List[IPTVChannel]:
        """
        æ ¹æ®åŸŸåé¢‘ç‡æ’åºé¢‘é“åˆ—è¡¨
        
        Args:
            channels: åŸå§‹é¢‘é“åˆ—è¡¨
            
        Returns:
            List[IPTVChannel]: æŒ‰åŸŸåé¢‘ç‡æ’åºåçš„é¢‘é“åˆ—è¡¨
        """
        if not channels:
            return channels
        
        def get_domain_frequency(channel: IPTVChannel) -> Tuple[int, str]:
            """è·å–åŸŸåé¢‘ç‡ï¼Œç”¨äºæ’åº"""
            domain = self.extract_domain_or_ip(channel.url)
            frequency = self.domain_counter.get(domain, 0)
            # è¿”å›è´Ÿçš„é¢‘ç‡å€¼ï¼Œè¿™æ ·é¢‘ç‡é«˜çš„ä¼šæ’åœ¨å‰é¢
            # ç¬¬äºŒä¸ªå€¼æ˜¯åŸŸåï¼Œç”¨äºç›¸åŒé¢‘ç‡æ—¶çš„äºŒçº§æ’åº
            return (-frequency, domain)
        
        sorted_channels = sorted(channels, key=get_domain_frequency)
        
        # è®°å½•æ’åºç»“æœ
        if len(channels) > 1:
            logger.debug(f"é¢‘é“æ’åº: {channels[0].name}")
            for i, channel in enumerate(sorted_channels[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                domain = self.extract_domain_or_ip(channel.url)
                frequency = self.domain_counter.get(domain, 0)
                logger.debug(f"  {i}. {domain} (é¢‘ç‡: {frequency})")
        
        return sorted_channels


class ResultFormatter:
    """ç»“æœæ ¼å¼åŒ–å™¨"""
    
    def __init__(self, domain_processor: DomainFrequencyProcessor = None):
        self.domain_processor = domain_processor
    
    def write_results_to_file(self, all_results: Dict[str, Dict[str, List[IPTVChannel]]], 
                            output_file: str = "result.txt", 
                            original_groups: List[ChannelGroup] = None) -> int:
        """
        å°†ç»“æœå†™å…¥æ–‡ä»¶ï¼ŒæŒ‰è¾“å…¥æ–‡ä»¶é¡ºåºæ’åºï¼Œå¹¶åœ¨ç¬¬ä¸€ä¸ªé¢‘é“å‰æ·»åŠ æ—¶é—´æˆ³é¢‘é“
        
        Args:
            all_results: æ‰€æœ‰æœç´¢ç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶å
            original_groups: åŸå§‹é¢‘é“åˆ†ç»„åˆ—è¡¨ï¼ˆç”¨äºä¿æŒé¡ºåºï¼‰
            
        Returns:
            int: æ€»çš„æœ‰æ•ˆé“¾æ¥æ•°
        """
        total_links = 0
        
        # è·å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆé¢‘é“çš„é“¾æ¥ï¼Œç”¨äºæ—¶é—´æˆ³é¢‘é“
        first_channel_url = self._get_first_valid_channel_url(all_results)
        
        # ç”Ÿæˆæ—¶é—´æˆ³é¢‘é“åç§°ï¼ˆyyyy-MM-dd HH:mmæ ¼å¼ï¼ŒåŒ—äº¬æ—¶é—´ï¼‰
        beijing_tz = timezone(timedelta(hours=8))  # åŒ—äº¬æ—¶é—´ UTC+8
        timestamp = datetime.now(beijing_tz).strftime("%Y-%m-%d %H:%M")
        timestamp_channel_name = f"æ›´æ–°æ—¶é—´({timestamp})"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                is_first_group = True
                
                # å¦‚æœæœ‰åŸå§‹åˆ†ç»„ä¿¡æ¯ï¼ŒæŒ‰ç…§åŸå§‹é¡ºåºè¾“å‡º
                if original_groups:
                    for group in original_groups:
                        group_name = group.name
                        
                        # æ£€æŸ¥è¯¥åˆ†ç»„æ˜¯å¦æœ‰ç»“æœ
                        if group_name not in all_results:
                            continue
                            
                        group_channels = all_results[group_name]
                        
                        # å†™å…¥åˆ†ç»„æ ‡é¢˜
                        f.write(f"{group_name},#genre#\n")
                        
                        # åœ¨ç¬¬ä¸€ä¸ªåˆ†ç»„çš„ç¬¬ä¸€ä¸ªé¢‘é“å‰æ·»åŠ æ—¶é—´æˆ³é¢‘é“
                        if is_first_group and first_channel_url:
                            f.write(f"{timestamp_channel_name},{first_channel_url}\n")
                            total_links += 1
                            logger.info(f"æ·»åŠ æ—¶é—´æˆ³é¢‘é“: {timestamp_channel_name}")
                            is_first_group = False
                        
                        # æŒ‰ç…§è¾“å…¥æ–‡ä»¶ä¸­çš„é¢‘é“é¡ºåºè¾“å‡º
                        for channel_name in group.channels:
                            if channel_name in group_channels:
                                channels = group_channels[channel_name]
                                if channels and len(channels) > 0:
                                    # å¦‚æœæœ‰åŸŸåå¤„ç†å™¨ï¼ŒæŒ‰é¢‘ç‡æ’åº
                                    if self.domain_processor:
                                        channels = self.domain_processor.sort_channels_by_domain_frequency(channels)
                                    
                                    # å†™å…¥é¢‘é“é“¾æ¥ - æœ‰ä¸€ä¸ªç®—ä¸€ä¸ª
                                    for channel in channels:
                                        f.write(f"{channel.name},{channel.url}\n")
                                        total_links += 1
                                    logger.debug(f"è¾“å‡ºé¢‘é“ {channel_name}: {len(channels)} ä¸ªé“¾æ¥")
                                else:
                                    # åªæœ‰å®Œå…¨æ²¡æœ‰æœ‰æ•ˆé“¾æ¥ï¼ˆ0ä¸ªï¼‰çš„é¢‘é“æ‰è·³è¿‡
                                    logger.info(f"è·³è¿‡æ— æœ‰æ•ˆé“¾æ¥çš„é¢‘é“: {channel_name}")
                                    continue
                else:
                    # å›é€€åˆ°åŸæ¥çš„é€»è¾‘ï¼ˆå¦‚æœæ²¡æœ‰åŸå§‹åˆ†ç»„ä¿¡æ¯ï¼‰
                    for group_name, group_channels in all_results.items():
                        # å†™å…¥åˆ†ç»„æ ‡é¢˜
                        f.write(f"{group_name},#genre#\n")
                        
                        # åœ¨ç¬¬ä¸€ä¸ªåˆ†ç»„çš„ç¬¬ä¸€ä¸ªé¢‘é“å‰æ·»åŠ æ—¶é—´æˆ³é¢‘é“
                        if is_first_group and first_channel_url:
                            f.write(f"{timestamp_channel_name},{first_channel_url}\n")
                            total_links += 1
                            logger.info(f"æ·»åŠ æ—¶é—´æˆ³é¢‘é“: {timestamp_channel_name}")
                            is_first_group = False
                        
                        for channel_name, channels in group_channels.items():
                            if channels and len(channels) > 0:
                                # å¦‚æœæœ‰åŸŸåå¤„ç†å™¨ï¼ŒæŒ‰é¢‘ç‡æ’åº
                                if self.domain_processor:
                                    channels = self.domain_processor.sort_channels_by_domain_frequency(channels)
                                
                                # å†™å…¥é¢‘é“é“¾æ¥ - æœ‰ä¸€ä¸ªç®—ä¸€ä¸ª
                                for channel in channels:
                                    f.write(f"{channel.name},{channel.url}\n")
                                    total_links += 1
                                logger.debug(f"è¾“å‡ºé¢‘é“ {channel_name}: {len(channels)} ä¸ªé“¾æ¥")
                            else:
                                # åªæœ‰å®Œå…¨æ²¡æœ‰æœ‰æ•ˆé“¾æ¥ï¼ˆ0ä¸ªï¼‰çš„é¢‘é“æ‰è·³è¿‡
                                logger.info(f"è·³è¿‡æ— æœ‰æ•ˆé“¾æ¥çš„é¢‘é“: {channel_name}")
                                continue
            
            logger.info(f"ç»“æœå·²å†™å…¥æ–‡ä»¶: {output_file}")
            logger.info(f"æ€»è®¡æœ‰æ•ˆé“¾æ¥: {total_links} ä¸ª (åŒ…å«1ä¸ªæ—¶é—´æˆ³é¢‘é“)")
            
            if self.domain_processor:
                logger.info("é“¾æ¥å·²æŒ‰åŸŸå/IPå‡ºç°é¢‘ç‡æ’åºï¼Œé¢‘ç‡é«˜çš„æ’åœ¨å‰é¢")
            
        except Exception as e:
            logger.error(f"å†™å…¥ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            raise
        
        return total_links
    
    def _get_first_valid_channel_url(self, all_results: Dict[str, Dict[str, List[IPTVChannel]]]) -> Optional[str]:
        """
        è·å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆé¢‘é“çš„é“¾æ¥ï¼Œç”¨äºæ—¶é—´æˆ³é¢‘é“
        
        Args:
            all_results: æ‰€æœ‰æœç´¢ç»“æœ
            
        Returns:
            Optional[str]: ç¬¬ä¸€ä¸ªæœ‰æ•ˆé¢‘é“çš„URLï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        for group_name, group_channels in all_results.items():
            for channel_name, channels in group_channels.items():
                if channels and len(channels) > 0:
                    # è¿”å›ç¬¬ä¸€ä¸ªé¢‘é“çš„ç¬¬ä¸€ä¸ªé“¾æ¥
                    return channels[0].url
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆé“¾æ¥ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤çš„å ä½URL
        logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“é“¾æ¥ï¼Œæ—¶é—´æˆ³é¢‘é“å°†ä½¿ç”¨å ä½é“¾æ¥")
        return "http://placeholder.example/timestamp.m3u8"


@dataclass
class ProcessorConfig:
    """æ‰¹é‡å¤„ç†å™¨é…ç½®"""
    searcher_name: str = "tonkiang"      # ä½¿ç”¨çš„æœç´¢å™¨åç§°
    input_file: str = "LiveChannel.txt"  # è¾“å…¥æ–‡ä»¶
    output_file: str = "result.txt"      # è¾“å‡ºæ–‡ä»¶
    concurrent_groups: int = 2           # å¹¶å‘å¤„ç†çš„åˆ†ç»„æ•°
    max_workers_per_group: int = 4       # æ¯ä¸ªåˆ†ç»„çš„æœ€å¤§å¹¶å‘æ•°
    
    # æœç´¢å™¨é…ç½®
    max_results_per_channel: int = 10    # æ¯ä¸ªé¢‘é“æœ€å¤§ç»“æœæ•°
    search_timeout: int = 15             # æœç´¢è¶…æ—¶æ—¶é—´
    min_resolution: int = 0              # æœ€å°åˆ†è¾¨ç‡è¦æ±‚ (0=ä¸é™åˆ¶, 720=720p+, 1080=1080p+)
    enable_validation: bool = True       # æ˜¯å¦å¯ç”¨é“¾æ¥éªŒè¯
    enable_cache: bool = True            # æ˜¯å¦å¯ç”¨æœç´¢ç¼“å­˜
    min_valid_links: int = 5             # æ¯ä¸ªé¢‘é“æœ€å°‘æœ‰æ•ˆé“¾æ¥æ•°ï¼Œè¾¾åˆ°ååœæ­¢éªŒè¯
    
    def to_search_config(self) -> SearchConfig:
        """è½¬æ¢ä¸ºæœç´¢å™¨é…ç½®"""
        return SearchConfig(
            max_results=self.max_results_per_channel,
            timeout=self.search_timeout,
            min_resolution=self.min_resolution,
            enable_validation=self.enable_validation,
            enable_cache=self.enable_cache,
            concurrent_workers=self.max_workers_per_group,
            min_valid_links=self.min_valid_links
        )


class ModularBatchProcessor:
    """æ¨¡å—åŒ–æ‰¹é‡å¤„ç†å™¨"""
    
    def __init__(self, config: ProcessorConfig = None):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            config: å¤„ç†å™¨é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config if config else ProcessorConfig()
        self.file_parser = ChannelFileParser()
        
        # åˆ›å»ºåŸŸåé¢‘ç‡å¤„ç†å™¨
        self.domain_processor = DomainFrequencyProcessor()
        self.result_formatter = ResultFormatter(domain_processor=self.domain_processor)
        
        # åˆ›å»ºæœç´¢å™¨
        self.searcher = self._create_searcher()
        
        logger.info(f"æ¨¡å—åŒ–æ‰¹é‡å¤„ç†å™¨å·²åˆå§‹åŒ–ï¼Œä½¿ç”¨æœç´¢å™¨: {self.searcher.site_name}")
        logger.info("å¯ç”¨åŸŸåé¢‘ç‡æ’åºåŠŸèƒ½ï¼Œé«˜é¢‘åŸŸå/IPçš„é“¾æ¥å°†ä¼˜å…ˆæ˜¾ç¤º")
    
    def _create_searcher(self) -> BaseIPTVSearcher:
        """åˆ›å»ºæœç´¢å™¨å®ä¾‹"""
        try:
            search_config = self.config.to_search_config()
            searcher = SearcherFactory.create_searcher(self.config.searcher_name, search_config)
            logger.info(f"æœç´¢å™¨åˆ›å»ºæˆåŠŸ: {searcher.get_site_info()}")
            return searcher
        except Exception as e:
            logger.error(f"åˆ›å»ºæœç´¢å™¨å¤±è´¥: {e}")
            # å›é€€åˆ°é»˜è®¤çš„ Tonkiang æœç´¢å™¨
            logger.info("å›é€€åˆ°é»˜è®¤ Tonkiang æœç´¢å™¨")
            return TonkiangSearcher(self.config.to_search_config())
    
    def switch_searcher(self, searcher_name: str):
        """
        åˆ‡æ¢æœç´¢å™¨
        
        Args:
            searcher_name: æ–°çš„æœç´¢å™¨åç§°
        """
        old_name = self.searcher.site_name
        try:
            self.config.searcher_name = searcher_name
            self.searcher = self._create_searcher()
            logger.info(f"æœç´¢å™¨åˆ‡æ¢æˆåŠŸ: {old_name} -> {self.searcher.site_name}")
        except Exception as e:
            logger.error(f"åˆ‡æ¢æœç´¢å™¨å¤±è´¥: {e}")
            logger.info(f"ä¿æŒä½¿ç”¨åŸæœç´¢å™¨: {old_name}")
    
    def list_available_searchers(self) -> List[str]:
        """è·å–å¯ç”¨çš„æœç´¢å™¨åˆ—è¡¨"""
        return SearcherFactory.list_searchers()
    
    def process_single_channel(self, channel_name: str) -> List[IPTVChannel]:
        """
        å¤„ç†å•ä¸ªé¢‘é“
        
        Args:
            channel_name: é¢‘é“åç§°
            
        Returns:
            List[IPTVChannel]: æ‰¾åˆ°çš„æœ‰æ•ˆé¢‘é“åˆ—è¡¨
        """
        try:
            start_time = time.time()
            
            # ä½¿ç”¨æœç´¢å™¨æœç´¢é¢‘é“
            channels = self.searcher.search_channels(channel_name)
            
            search_time = time.time() - start_time
            
            if channels:
                logger.info(f"    âœ“ {channel_name}: {len(channels)} ä¸ªæœ‰æ•ˆé“¾æ¥ ({search_time:.2f}s)")
            else:
                logger.warning(f"    âœ— {channel_name}: æ— æœ‰æ•ˆé“¾æ¥")
            
            return channels
            
        except Exception as e:
            logger.error(f"    âœ— {channel_name}: å¤„ç†å¤±è´¥ - {e}")
            return []
    
    def process_group_concurrent(self, group: ChannelGroup) -> Dict[str, List[IPTVChannel]]:
        """
        å¤„ç†åˆ†ç»„ä¸­çš„æ‰€æœ‰é¢‘é“ - æ”¯æŒä¸²è¡Œå’Œå¹¶å‘æ¨¡å¼
        
        Args:
            group: é¢‘é“åˆ†ç»„
            
        Returns:
            Dict[str, List[IPTVChannel]]: é¢‘é“åç§°åˆ°é¢‘é“åˆ—è¡¨çš„æ˜ å°„
        """
        group_channels = {}
        
        # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä¸²è¡Œæ¨¡å¼ï¼ˆåçˆ¬è™«éœ€è¦ï¼‰
        force_serial = self.config.max_workers_per_group == 1
        
        if force_serial:
            logger.info(f"  ä½¿ç”¨ä¸²è¡Œæ¨¡å¼å¤„ç† {len(group.channels)} ä¸ªé¢‘é“")
            # ä¸²è¡Œå¤„ç†ï¼Œå®Œå…¨é¿å…å¹¶å‘
            for i, channel_name in enumerate(group.channels, 1):
                logger.info(f"  [{i}/{len(group.channels)}] å¤„ç†é¢‘é“: {channel_name}")
                try:
                    channels = self.process_single_channel(channel_name)
                    group_channels[channel_name] = channels
                    
                    # é¢‘é“é—´é¢å¤–å»¶è¿Ÿï¼ˆåçˆ¬è™«ï¼‰
                    if i < len(group.channels):  # ä¸æ˜¯æœ€åä¸€ä¸ªé¢‘é“
                        import time
                        import random
                        delay = random.uniform(2.0, 5.0)
                        logger.debug(f"  é¢‘é“é—´å»¶è¿Ÿ {delay:.1f}ç§’")
                        time.sleep(delay)
                        
                except Exception as e:
                    logger.error(f"    âœ— {channel_name}: å¤„ç†å¼‚å¸¸ - {e}")
                    group_channels[channel_name] = []
        else:
            # åŸæ¥çš„å¹¶å‘å¤„ç†
            with ThreadPoolExecutor(max_workers=self.config.max_workers_per_group) as executor:
                # æäº¤æ‰€æœ‰æœç´¢ä»»åŠ¡
                future_to_channel = {
                    executor.submit(self.process_single_channel, channel_name): channel_name
                    for channel_name in group.channels
                }
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_channel):
                    channel_name = future_to_channel[future]
                    try:
                        channels = future.result()
                        group_channels[channel_name] = channels
                    except Exception as e:
                        logger.error(f"    âœ— {channel_name}: å¤„ç†å¼‚å¸¸ - {e}")
                        group_channels[channel_name] = []
        
        return group_channels
    
    def process_all_groups(self, groups: List[ChannelGroup]) -> Dict[str, Dict[str, List[IPTVChannel]]]:
        """
        å¤„ç†æ‰€æœ‰åˆ†ç»„
        
        Args:
            groups: é¢‘é“åˆ†ç»„åˆ—è¡¨
            
        Returns:
            Dict[str, Dict[str, List[IPTVChannel]]]: åˆ†ç»„ç»“æœ
        """
        all_results = {}
        
        # ä¸²è¡Œå¤„ç†åˆ†ç»„ï¼ˆé¿å…è¿‡é«˜å¹¶å‘ï¼‰
        for i, group in enumerate(groups, 1):
            logger.info(f"å¤„ç†åˆ†ç»„ {i}/{len(groups)}: {group.name} ({len(group.channels)} ä¸ªé¢‘é“)")
            
            group_start_time = time.time()
            
            # å¹¶å‘å¤„ç†åˆ†ç»„å†…çš„é¢‘é“
            group_result = self.process_group_concurrent(group)
            
            group_time = time.time() - group_start_time
            valid_count = sum(len(channels) for channels in group_result.values())
            
            logger.info(f"    åˆ†ç»„ {group.name} å®Œæˆ: {valid_count} ä¸ªæœ‰æ•ˆé“¾æ¥ ({group_time:.2f}s)")
            
            all_results[group.name] = group_result
        
        return all_results
    
    def run(self):
        """è¿è¡Œæ‰¹é‡å¤„ç†"""
        start_time = time.time()
        
        print("=" * 60)
        print("æ¨¡å—åŒ–IPTVé¢‘é“æ‰¹é‡æœç´¢å’Œé“¾æ¥æå–å·¥å…·")
        print(f"å½“å‰æœç´¢å™¨: {self.searcher.site_name}")
        print(f"éªŒè¯ç­–ç•¥: æ¯é¢‘é“æ‰¾åˆ°{self.config.min_valid_links}ä¸ªæœ‰æ•ˆé“¾æ¥ååœæ­¢ (æç®€æ¨¡å¼)")
        print(f"æœç´¢é…ç½®: æœ€å¤§{self.config.max_results_per_channel}é“¾æ¥/é¢‘é“, "
              f"åˆ†è¾¨ç‡â‰¥{self.config.min_resolution}p, éªŒè¯{'å¼€å¯' if self.config.enable_validation else 'å…³é—­'}")
        print("æ™ºèƒ½ç‰¹æ€§: è·³è¿‡ä¸»é¡µè®¿é—® + ç›´æ¥æœç´¢ + å®Œå…¨ä¸²è¡Œ")
        print("=" * 60)
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(self.config.input_file):
            input_files = ["LiveChannel.txt", "livechannel.txt"]
            found_file = None
            for file in input_files:
                if os.path.exists(file):
                    found_file = file
                    break
            
            if found_file:
                self.config.input_file = found_file
                logger.info(f"æ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {found_file}")
            else:
                logger.error(f"æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {input_files}")
                print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ {self.config.input_file}")
                return
        
        # è§£æè¾“å…¥æ–‡ä»¶
        logger.info("1. è§£æé¢‘é“åˆ—è¡¨æ–‡ä»¶...")
        try:
            groups = self.file_parser.parse_channel_file(self.config.input_file)
            total_channels = sum(len(g.channels) for g in groups)
            logger.info(f"è§£æå®Œæˆï¼Œå…± {len(groups)} ä¸ªåˆ†ç»„ï¼Œ{total_channels} ä¸ªé¢‘é“")
            
            print(f"è¾“å…¥æ–‡ä»¶: {self.config.input_file}")
            print(f"é¢‘é“åˆ†ç»„: {len(groups)} ä¸ª")
            print(f"é¢‘é“æ•°é‡: {total_channels} ä¸ª")
            print(f"é¢„è®¡ç”¨æ—¶: {total_channels * 0.8:.0f} ç§’ (æ¨¡å—åŒ–å¤„ç†)")
            
        except Exception as e:
            logger.error(f"è§£æè¾“å…¥æ–‡ä»¶å¤±è´¥: {e}")
            print(f"âŒ è§£æè¾“å…¥æ–‡ä»¶å¤±è´¥: {e}")
            return
        
        print(f"\nğŸš€ è‡ªåŠ¨å¼€å§‹æ¨¡å—åŒ–æ‰¹é‡å¤„ç†...")
        print("-" * 40)
        
        # å¤„ç†æ‰€æœ‰åˆ†ç»„
        logger.info("2. å¼€å§‹æ¨¡å—åŒ–æœç´¢é¢‘é“æ’­æ”¾é“¾æ¥...")
        try:
            all_results = self.process_all_groups(groups)
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {e}")
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return
        
        # ç»Ÿè®¡åŸŸåé¢‘ç‡
        logger.info("3. ç»Ÿè®¡åŸŸå/IPå‡ºç°é¢‘ç‡...")
        try:
            self.domain_processor.collect_domain_stats(all_results)
        except Exception as e:
            logger.warning(f"åŸŸåé¢‘ç‡ç»Ÿè®¡å¤±è´¥: {e}")
        
        # ç”Ÿæˆç»“æœæ–‡ä»¶ï¼ˆåŒ…å«åŸŸåé¢‘ç‡æ’åºï¼‰
        logger.info("4. ç”Ÿæˆç»“æœæ–‡ä»¶...")
        try:
            total_valid = self.result_formatter.write_results_to_file(
                all_results, self.config.output_file, groups
            )
            
            processing_time = time.time() - start_time
            
            logger.info("=" * 60)
            logger.info("æ‰¹é‡å¤„ç†å®Œæˆ")
            logger.info(f"æ€»ç”¨æ—¶: {processing_time:.2f} ç§’")
            logger.info(f"æœ‰æ•ˆé“¾æ¥: {total_valid} ä¸ª")
            logger.info(f"è¾“å‡ºæ–‡ä»¶: {self.config.output_file}")
            logger.info("=" * 60)
            
            print(f"\næ¨¡å—åŒ–å¤„ç†å®Œæˆï¼")
            print(f"æ€»ç”¨æ—¶: {processing_time:.2f} ç§’")
            print(f"æœ‰æ•ˆé“¾æ¥: {total_valid} ä¸ª")
            print(f"ç»“æœæ–‡ä»¶: {self.config.output_file}")
            print(f"é“¾æ¥å·²æŒ‰åŸŸå/IPé¢‘ç‡æ™ºèƒ½æ’åº")
            
            # æ˜¾ç¤ºç»“æœæ–‡ä»¶çš„å‰å‡ è¡Œ
            if os.path.exists(self.config.output_file):
                print(f"\nç»“æœæ–‡ä»¶å‰10è¡Œé¢„è§ˆ:")
                with open(self.config.output_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[:10]
                    for i, line in enumerate(lines, 1):
                        print(f"  {i:2d}: {line.rstrip()}")
                
                if len(lines) == 10:
                    with open(self.config.output_file, 'r', encoding='utf-8') as f:
                        total_lines = len(f.readlines())
                        print(f"  ... (å…± {total_lines} è¡Œ)")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            print(f"âŒ ç”Ÿæˆç»“æœæ–‡ä»¶å¤±è´¥: {e}")


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    
    # æ˜¾ç¤ºå¯ç”¨çš„æœç´¢å™¨
    print("å¯ç”¨æœç´¢å™¨:")
    for name in SearcherFactory.list_searchers():
        print(f"  - {name}")
    print()
    
    # ä½¿ç”¨æ­£å¸¸å¹¶å‘é…ç½® - é‡æ–°åˆ†æå†…å®¹è¿‡çŸ­é—®é¢˜
    print("é…ç½®: ä½¿ç”¨æ­£å¸¸å¹¶å‘é…ç½®ï¼ˆåˆ†æå†…å®¹è¿‡çŸ­é—®é¢˜ï¼‰")
    config = ProcessorConfig(
        searcher_name="tonkiang",
        max_results_per_channel=8,     # æ¢å¤æ­£å¸¸è¯·æ±‚æ•°é‡
        search_timeout=30,             # æ­£å¸¸è¶…æ—¶
        min_resolution=0,
        enable_validation=True,        # å¯ç”¨éªŒè¯
        enable_cache=True,
        concurrent_groups=2,           # 2ä¸ªå¹¶å‘ç»„
        max_workers_per_group=4,       # æ¯ç»„3ä¸ªå·¥ä½œçº¿ç¨‹
        min_valid_links=3              # æ­£å¸¸è¦æ±‚
    )
    
    # åˆ›å»ºå¹¶è¿è¡Œå¤„ç†å™¨
    processor = ModularBatchProcessor(config)
    processor.run()


if __name__ == "__main__":
    main()
